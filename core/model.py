"""
Hidden Markov Model Implementation

Bu modÃ¼l HMM tabanlÄ± POS tagger'Ä±n ana model sÄ±nÄ±fÄ±nÄ± iÃ§erir.
Model eÄŸitimi, kaydetme, yÃ¼kleme ve tahmin fonksiyonlarÄ± saÄŸlar.
"""

import pickle
import os
from .counts import HMMCounts


class HMMModel:
    """
    Hidden Markov Model ana sÄ±nÄ±fÄ±.
    
    Bu sÄ±nÄ±f HMM'in tÃ¼m parametrelerini (transition ve emission probabilities)
    tutar ve model eÄŸitimi, kaydetme/yÃ¼kleme iÅŸlemlerini yapar.
    """
    
    def __init__(self):
        """
        HMMModel constructor. Model parametrelerini initialize eder.
        """
        self.counts = None          # HMMCounts instance
        self.tags = set()          # TÃ¼m POS tag'leri
        self.vocab = set()         # TÃ¼m kelimeler
        self.smoothing = 0.1       # Smoothing parametresi
        self.is_trained = False    # Model eÄŸitildi mi?
        
        # Model meta bilgileri
        self.model_info = {
            'version': '1.0',
            'training_sentences': 0,
            'training_tokens': 0,
            'tag_count': 0,
            'vocab_size': 0
        }
        
        # Metadata alias for compatibility
        self.metadata = self.model_info
    
    def train(self, train_sentences, smoothing=0.1):
        """
        HMM modelini verilen cÃ¼mlelerle eÄŸitir.
        
        Args:
            train_sentences (list): EÄŸitim cÃ¼mleleri listesi.
                                  Her cÃ¼mle token dict'leri iÃ§erir.
            smoothing (float): Add-k smoothing parametresi
        
        Example:
            >>> model = HMMModel()
            >>> sentences = [[{'form': 'Bu', 'upos': 'PRON'}, {'form': 'kitap', 'upos': 'NOUN'}]]
            >>> model.train(sentences, smoothing=0.1)
        """
        if not train_sentences:
            raise ValueError("EÄŸitim cÃ¼mleleri boÅŸ olamaz!")
        
        print(f"ğŸš€ HMM Model EÄŸitimi BaÅŸlÄ±yor...")
        print(f"Smoothing parametresi: {smoothing}")
        
        # HMM sayÄ±mlarÄ±nÄ± hesapla
        self.counts = HMMCounts()
        self.counts.count_from_sentences(train_sentences)
        
        # Model parametrelerini ayarla
        self.smoothing = smoothing
        self.tags = set(self.counts.tag_counts.keys())
        self.tags.discard("<START>")  # START tag'ini Ã§Ä±kar
        self.tags.discard("<END>")    # END tag'ini Ã§Ä±kar
        self.vocab = self.counts.vocab.copy()
        
        # Model bilgilerini gÃ¼ncelle
        self.model_info.update({
            'training_sentences': self.counts.total_sentences,
            'training_tokens': self.counts.total_tokens,
            'tag_count': len(self.tags),
            'vocab_size': len(self.vocab)
        })
        
        self.is_trained = True
        
        self._print_training_summary()
    
    def save(self, filepath):
        """
        EÄŸitilmiÅŸ modeli dosyaya kaydeder.
        
        Args:
            filepath (str): Model dosyasÄ±nÄ±n kaydedileceÄŸi yol
        
        Raises:
            ValueError: Model eÄŸitilmemiÅŸse
            IOError: Dosya yazma hatasÄ±
        """
        if not self.is_trained:
            raise ValueError("Model henÃ¼z eÄŸitilmemiÅŸ! Ã–nce train() metodunu Ã§aÄŸÄ±rÄ±n.")
        
        # Dosya dizinini oluÅŸtur
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        try:
            model_data = {
                'counts': self.counts,
                'tags': self.tags,
                'vocab': self.vocab,
                'smoothing': self.smoothing,
                'model_info': self.model_info,
                'is_trained': self.is_trained
            }
            
            with open(filepath, 'wb') as f:
                pickle.dump(model_data, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            print(f"âœ… Model baÅŸarÄ±yla kaydedildi: {filepath}")
            self._print_file_size(filepath)
            
        except Exception as e:
            raise IOError(f"Model kaydedilemedi: {e}")
    
    @classmethod
    def load(cls, filepath):
        """
        KaydedilmiÅŸ modeli dosyadan yÃ¼kler.
        
        Args:
            filepath (str): YÃ¼klenecek model dosyasÄ±nÄ±n yolu
        
        Raises:
            FileNotFoundError: Dosya bulunamadÄ±ysa
            ValueError: Model formatÄ± hatalÄ±ysa
        """
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Model dosyasÄ± bulunamadÄ±: {filepath}")
        
        try:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
            
            # Yeni model instance oluÅŸtur
            model = cls()
            
            # Model verilerini yÃ¼kle
            model.counts = model_data['counts']
            model.tags = model_data['tags']
            model.vocab = model_data['vocab']
            model.smoothing = model_data['smoothing']
            model.model_info = model_data.get('model_info', {})
            model.metadata = model.model_info  # Alias
            model.is_trained = model_data.get('is_trained', True)
            
            print(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi: {filepath}")
            model._print_model_info()
            
            return model
            
        except Exception as e:
            raise ValueError(f"Model yÃ¼klenemedi: {e}")
    
    def get_transition_prob(self, prev_tag, curr_tag):
        """
        Ä°ki tag arasÄ±ndaki geÃ§iÅŸ olasÄ±lÄ±ÄŸÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
        
        Args:
            prev_tag (str): Ã–nceki tag
            curr_tag (str): Åimdiki tag
        
        Returns:
            float: Log geÃ§iÅŸ olasÄ±lÄ±ÄŸÄ±
        """
        if not self.is_trained:
            raise ValueError("Model eÄŸitilmemiÅŸ!")
        
        return self.counts.get_transition_prob(prev_tag, curr_tag, self.smoothing)
    
    def get_emission_prob(self, tag, word):
        """
        Tag'den kelime emisyon olasÄ±lÄ±ÄŸÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
        
        Args:
            tag (str): POS tag
            word (str): Kelime
        
        Returns:
            float: Log emisyon olasÄ±lÄ±ÄŸÄ±
        """
        if not self.is_trained:
            raise ValueError("Model eÄŸitilmemiÅŸ!")
        
        return self.counts.get_emission_prob(tag, word, self.smoothing)
    
    def viterbi_decode(self, words):
        """
        Viterbi algoritmasÄ± ile cÃ¼mledeki kelimeler iÃ§in en olasÄ± tag sequence'ini bulur.
        
        Args:
            words (list): Kelime listesi
        
        Returns:
            list: En olasÄ± POS tag sequence'i
        """
        if not self.is_trained:
            raise ValueError("Model eÄŸitilmemiÅŸ!")
        
        from .viterbi import ViterbiDecoder
        decoder = ViterbiDecoder(self)
        return decoder.decode(words)
    
    def predict_tag(self, word):
        """
        Tek bir kelime iÃ§in en olasÄ± tag'i tahmin eder.
        
        Args:
            word (str): Tahmin edilecek kelime
        
        Returns:
            str: En olasÄ± POS tag
        """
        if not self.is_trained:
            raise ValueError("Model eÄŸitilmemiÅŸ!")
        
        best_tag = None
        best_prob = float('-inf')
        
        for tag in self.tags:
            prob = self.get_emission_prob(tag, word)
            if prob > best_prob:
                best_prob = prob
                best_tag = tag
        
        return best_tag if best_tag else 'NOUN'  # Fallback
    
    def get_model_statistics(self):
        """
        Model istatistiklerini dÃ¶ndÃ¼rÃ¼r.
        
        Returns:
            dict: Model istatistikleri
        """
        if not self.is_trained:
            return {"error": "Model eÄŸitilmemiÅŸ"}
        
        stats = self.model_info.copy()
        stats.update({
            'smoothing_parameter': self.smoothing,
            'transition_pairs': sum(len(v) for v in self.counts.transition_counts.values()),
            'emission_pairs': sum(len(v) for v in self.counts.emission_counts.values()),
            'most_common_tags': self.counts.tag_counts.most_common(5)
        })
        
        return stats
    
    def _print_training_summary(self):
        """EÄŸitim Ã¶zetini yazdÄ±rÄ±r."""
        print(f"\nğŸ¯ Model EÄŸitimi TamamlandÄ±!")
        print(f"{'='*40}")
        print(f"EÄŸitim cÃ¼mleleri: {self.model_info['training_sentences']:,}")
        print(f"EÄŸitim token'larÄ±: {self.model_info['training_tokens']:,}")
        print(f"POS tag sayÄ±sÄ±: {self.model_info['tag_count']}")
        print(f"Vocabulary boyutu: {self.model_info['vocab_size']:,}")
        print(f"Smoothing: {self.smoothing}")
        
        print(f"\nPOS Tag'leri: {', '.join(sorted(self.tags))}")
    
    def _print_model_info(self):
        """YÃ¼klenen model bilgilerini yazdÄ±rÄ±r."""
        print(f"\nğŸ“‹ Model Bilgileri:")
        print(f"{'='*30}")
        for key, value in self.model_info.items():
            if isinstance(value, (int, float)):
                if isinstance(value, int) and value > 1000:
                    print(f"{key}: {value:,}")
                else:
                    print(f"{key}: {value}")
            else:
                print(f"{key}: {value}")
    
    def _print_file_size(self, filepath):
        """Dosya boyutunu yazdÄ±rÄ±r."""
        try:
            size_bytes = os.path.getsize(filepath)
            if size_bytes > 1024 * 1024:  # MB
                size_str = f"{size_bytes / (1024*1024):.1f} MB"
            elif size_bytes > 1024:  # KB
                size_str = f"{size_bytes / 1024:.1f} KB"
            else:
                size_str = f"{size_bytes} bytes"
            
            print(f"ğŸ“ Dosya boyutu: {size_str}")
        except:
            pass
    
    def validate_model(self):
        """
        Model tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol eder.
        
        Returns:
            tuple: (is_valid, error_messages)
        """
        errors = []
        
        if not self.is_trained:
            errors.append("Model eÄŸitilmemiÅŸ")
            return False, errors
        
        if not self.counts:
            errors.append("HMM counts bulunamadÄ±")
        
        if not self.tags:
            errors.append("POS tag seti boÅŸ")
        
        if not self.vocab:
            errors.append("Vocabulary boÅŸ")
        
        if len(self.tags) < 2:
            errors.append("En az 2 POS tag gerekli")
        
        return len(errors) == 0, errors 