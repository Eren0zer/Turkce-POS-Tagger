#!/usr/bin/env python3
"""
HMM POS Tagger - Interactive Demo

Bu script eÄŸitilmiÅŸ HMM modelini kullanarak interaktif bir
POS tagging demo'su sunar. Ã‡eÅŸitli test modlarÄ± ve analiz 
seÃ§enekleri iÃ§erir.

Usage:
    python scripts/05_interactive_demo.py
    
Input:
    - models/hmm_model.pkl (eÄŸitilmiÅŸ model)
    
Features:
    - Tek cÃ¼mle tagging
    - Batch tagging
    - Model analizi
    - Performance benchmarking
    - Ã–rnek cÃ¼mleler
"""

import os
import sys
import time
import json
from datetime import datetime
import stanza

# Proje core modÃ¼llerini import et
sys.path.append(os.path.abspath('.'))
from core import HMMModel

# KonfigÃ¼rasyon
MODEL_FILE = 'models/hmm_model.pkl'
DEMO_LOG_FILE = 'models/demo_session.log'

# Ã–rnek TÃ¼rkÃ§e cÃ¼mleler (Ã§eÅŸitli zorluk seviyeleri)
SAMPLE_SENTENCES = {
    'Basit': [
        "Ben eve gidiyorum.",
        "Kedi uyuyor.",
        "Su iÃ§tim.",
        "Okul bÃ¼yÃ¼k.",
        "Kitap masa Ã¼zerinde."
    ],
    'Orta': [
        "BugÃ¼n hava Ã§ok gÃ¼zel.",
        "Ã–ÄŸrenciler derse katÄ±lmÄ±yor.",
        "TÃ¼rkiye'nin baÅŸkenti Ankara'dÄ±r.",
        "Pazartesi gÃ¼nÃ¼ iÅŸe gitmek zorundayÄ±m.",
        "Annem bana hediye almÄ±ÅŸ."
    ],
    'KarmaÅŸÄ±k': [
        "Yapay zeka teknolojilerinin geliÅŸmesiyle birlikte doÄŸal dil iÅŸleme alanÄ±nda Ã¶nemli ilerlemeler kaydedilmektedir.",
        "Ãœniversitedeki araÅŸtÄ±rmacÄ±lar yeni bir algoritma geliÅŸtirerek bu problemi Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±yorlar.",
        "KÃ¼reselleÅŸmenin etkisiyle ekonomik dengeler deÄŸiÅŸirken, toplumsal yapÄ±lar da bu durumdan etkilenmektedir.",
        "Bilgisayar mÃ¼hendisliÄŸi Ã¶ÄŸrencilerinin programlama becerilerini geliÅŸtirmeleri iÃ§in sÃ¼rekli pratik yapmalarÄ± gerekmektedir.",
        "Ã‡evre kirliliÄŸinin artmasÄ± nedeniyle yenilenebilir enerji kaynaklarÄ±na olan ilgi her geÃ§en gÃ¼n artmaktadÄ±r."
    ]
}

# Demo seÃ§enekleri
DEMO_OPTIONS = {
    '1': 'Tek CÃ¼mle Tagging',
    '2': 'Batch Tagging',
    '3': 'Ã–rnek CÃ¼mleler Testi',
    '4': 'Model Analizi',
    '5': 'Performance Benchmark',
    '6': 'Model Ä°statistikleri',
    '7': 'HakkÄ±nda',
    'q': 'Ã‡Ä±kÄ±ÅŸ'
}

# Stanza pipeline'Ä± baÅŸlat (tokenizer iÃ§in)
stanza_tokenizer = stanza.Pipeline('tr', processors='tokenize', use_gpu=False, verbose=False)

def stanza_tokenize(sentence):
    """
    Stanza ile TÃ¼rkÃ§e tokenizasyonu yapar.
    Args:
        sentence (str): CÃ¼mle
    Returns:
        list: Token listesi
    """
    # CÃ¼mle sonu noktalama yoksa ekle
    if not sentence.strip().endswith(('.', '!', '?')):
        sentence = sentence.strip() + '.'
    doc = stanza_tokenizer(sentence)
    tokens = []
    for sent in doc.sentences:
        tokens.extend([word.text for word in sent.words])
    return tokens

class DemoSession:
    """Demo oturumu iÃ§in log ve istatistik tutma."""
    
    def __init__(self):
        self.start_time = datetime.now()
        self.tagged_sentences = 0
        self.total_tokens = 0
        self.total_time = 0.0
        self.session_log = []
    
    def log_tagging(self, sentence, tags, processing_time):
        """Tagging iÅŸlemini logla."""
        self.tagged_sentences += 1
        self.total_tokens += len(tags)
        self.total_time += processing_time
        
        log_entry = {
            'timestamp': datetime.now().strftime('%H:%M:%S'),
            'sentence': sentence,
            'tags': tags,
            'processing_time': processing_time,
            'token_count': len(tags)
        }
        self.session_log.append(log_entry)
    
    def get_stats(self):
        """Oturum istatistiklerini dÃ¶ndÃ¼r."""
        duration = (datetime.now() - self.start_time).total_seconds()
        avg_time_per_sentence = self.total_time / self.tagged_sentences if self.tagged_sentences > 0 else 0
        avg_time_per_token = self.total_time / self.total_tokens if self.total_tokens > 0 else 0
        
        return {
            'session_duration': duration,
            'tagged_sentences': self.tagged_sentences,
            'total_tokens': self.total_tokens,
            'total_processing_time': self.total_time,
            'avg_time_per_sentence': avg_time_per_sentence,
            'avg_time_per_token': avg_time_per_token
        }
    
    def save_log(self):
        """Oturum logunu dosyaya kaydet."""
        if not self.session_log:
            return
        
        log_data = {
            'session_info': {
                'start_time': self.start_time.strftime('%Y-%m-%d %H:%M:%S'),
                'end_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'stats': self.get_stats()
            },
            'tagging_log': self.session_log
        }
        
        try:
            with open(DEMO_LOG_FILE, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“ Oturum logu kaydedildi: {DEMO_LOG_FILE}")
        except Exception as e:
            print(f"âš ï¸  Log kaydedilemedi: {e}")


def load_model():
    """HMM modelini yÃ¼kler."""
    if not os.path.exists(MODEL_FILE):
        print(f"âŒ Model dosyasÄ± bulunamadÄ±: {MODEL_FILE}")
        print(f"Ã–nce modeli eÄŸitin: python scripts/02_train_model.py")
        return None
    
    try:
        print(f"ğŸ“‚ Model yÃ¼kleniyor: {MODEL_FILE}")
        model = HMMModel.load(MODEL_FILE)
        print(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi")
        return model
    except Exception as e:
        print(f"âŒ Model yÃ¼klenemedi: {e}")
        return None


def print_banner():
    """Demo baÅŸlÄ±k banner'Ä±nÄ± yazdÄ±rÄ±r."""
    print("â•”" + "="*70 + "â•—")
    print("â•‘" + " "*25 + "HMM POS TAGGER DEMO" + " "*25 + "â•‘")
    print("â•‘" + " "*22 + "TÃ¼rkÃ§e Kelime TÃ¼rÃ¼ Etiketleyici" + " "*17 + "â•‘")
    print("â•š" + "="*70 + "â•")
    print()


def print_menu():
    """Ana menÃ¼yÃ¼ yazdÄ±rÄ±r."""
    print(f"\n{'ğŸ“‹ ANA MENÃœ':^50}")
    print(f"{'='*50}")
    
    for key, description in DEMO_OPTIONS.items():
        emoji = "ğŸšª" if key == 'q' else f"{key}ï¸âƒ£"
        print(f"  {emoji} {key:2s} - {description}")
    
    print(f"{'='*50}")


def simple_tokenize(sentence):
    return stanza_tokenize(sentence)


def display_tagging_result(sentence, words, tags, processing_time):
    """Tagging sonucunu gÃ¼zel formatta gÃ¶sterir."""
    print(f"\nğŸ”¤ CÃ¼mle: {sentence}")
    print(f"â±ï¸  Ä°ÅŸlem sÃ¼resi: {processing_time:.3f} saniye")
    print(f"ğŸ“Š Kelime sayÄ±sÄ±: {len(words)}")
    print(f"{'='*60}")
    
    print(f"ğŸ·ï¸  POS Tagging Sonucu:")
    for i, (word, tag) in enumerate(zip(words, tags), 1):
        print(f"   {i:2d}. {word:20s} â†’ {tag}")


def single_sentence_demo(model, session):
    """Tek cÃ¼mle tagging demosu."""
    print(f"\nğŸ”¤ TEK CÃœMLE TAGGING")
    print(f"{'='*50}")
    print(f"TÃ¼rkÃ§e bir cÃ¼mle girin (boÅŸ enter ile ana menÃ¼ye dÃ¶nÃ¼n):")
    
    while True:
        try:
            sentence = input(f"\nğŸ“ CÃ¼mle: ").strip()
            
            if not sentence:
                break
            
            # Tokenize
            words = simple_tokenize(sentence)
            
            if not words:
                print(f"âš ï¸  GeÃ§erli bir cÃ¼mle girin")
                continue
            
            # Tag
            start_time = time.time()
            tags = model.viterbi_decode(words)
            processing_time = time.time() - start_time
            
            # Sonucu gÃ¶ster
            display_tagging_result(sentence, words, tags, processing_time)
            
            # Session'a kaydet
            session.log_tagging(sentence, tags, processing_time)
            
        except KeyboardInterrupt:
            print(f"\nğŸ‘‹ Ana menÃ¼ye dÃ¶nÃ¼lÃ¼yor...")
            break
        except Exception as e:
            print(f"âŒ Hata: {e}")


def batch_tagging_demo(model, session):
    """Batch tagging demosu."""
    print(f"\nğŸ“¦ BATCH TAGGING")
    print(f"{'='*50}")
    print(f"CÃ¼mleleri girin (her satÄ±ra bir cÃ¼mle, boÅŸ satÄ±r ile bitirin):")
    
    sentences = []
    print(f"\nğŸ“ CÃ¼mleler:")
    
    while True:
        try:
            sentence = input().strip()
            if not sentence:
                break
            sentences.append(sentence)
        except KeyboardInterrupt:
            print(f"\nğŸ‘‹ Ana menÃ¼ye dÃ¶nÃ¼lÃ¼yor...")
            return
    
    if not sentences:
        print(f"âš ï¸  HiÃ§ cÃ¼mle girilmedi")
        return
    
    print(f"\nğŸ”„ {len(sentences)} cÃ¼mle iÅŸleniyor...")
    
    total_start = time.time()
    
    for i, sentence in enumerate(sentences, 1):
        print(f"\n--- CÃ¼mle {i}/{len(sentences)} ---")
        
        words = simple_tokenize(sentence)
        if not words:
            print(f"âš ï¸  GeÃ§ersiz cÃ¼mle atlanÄ±yor: {sentence}")
            continue
        
        start_time = time.time()
        tags = model.viterbi_decode(words)
        processing_time = time.time() - start_time
        
        display_tagging_result(sentence, words, tags, processing_time)
        session.log_tagging(sentence, tags, processing_time)
    
    total_time = time.time() - total_start
    print(f"\nğŸ“Š Batch Ä°ÅŸlem Ã–zeti:")
    print(f"   Ä°ÅŸlenen cÃ¼mle: {len(sentences)}")
    print(f"   Toplam sÃ¼re: {total_time:.3f} saniye")
    print(f"   CÃ¼mle baÅŸÄ±na: {total_time/len(sentences):.3f} saniye")


def sample_sentences_demo(model, session):
    """Ã–rnek cÃ¼mleler demosu."""
    print(f"\nğŸ§ª Ã–RNEK CÃœMLELER TESTÄ°")
    print(f"{'='*50}")
    
    for difficulty, sentences in SAMPLE_SENTENCES.items():
        print(f"\nğŸ“ˆ Zorluk Seviyesi: {difficulty}")
        print(f"{'-'*40}")
        
        for i, sentence in enumerate(sentences, 1):
            print(f"\n--- {difficulty} - {i}/{len(sentences)} ---")
            
            words = simple_tokenize(sentence)
            start_time = time.time()
            tags = model.viterbi_decode(words)
            processing_time = time.time() - start_time
            
            display_tagging_result(sentence, words, tags, processing_time)
            session.log_tagging(sentence, tags, processing_time)
        
        # KullanÄ±cÄ± onayÄ±
        if difficulty != list(SAMPLE_SENTENCES.keys())[-1]:  # Son deÄŸilse
            try:
                input(f"\nâ¸ï¸  Devam etmek iÃ§in Enter'a basÄ±n...")
            except KeyboardInterrupt:
                print(f"\nğŸ‘‹ Ana menÃ¼ye dÃ¶nÃ¼lÃ¼yor...")
                return


def model_analysis_demo(model):
    """Model analizi demosu."""
    print(f"\nğŸ”¬ MODEL ANALÄ°ZÄ°")
    print(f"{'='*50}")
    
    # Model istatistikleri
    stats = model.get_model_statistics()
    print(f"ğŸ“Š Model Ä°statistikleri:")
    print(f"   Vocabulary boyutu    : {stats['vocabulary_size']:,}")
    print(f"   POS tag sayÄ±sÄ±       : {stats['tag_set_size']:,}")
    print(f"   Emission parametreler: {stats['emission_params']:,}")
    print(f"   Transition parametr. : {stats['transition_params']:,}")
    
    # Model metadata
    print(f"\nğŸ“‹ Model Bilgileri:")
    for key, value in model.metadata.items():
        print(f"   {key:20s}: {value}")
    
    # Tag set analizi
    if hasattr(model, 'counts') and hasattr(model.counts, 'tag_set'):
        tags = sorted(model.counts.tag_set)
        print(f"\nğŸ·ï¸  Desteklenen POS TaglarÄ± ({len(tags)} adet):")
        
        # TaglarÄ± satÄ±r satÄ±r gÃ¶ster (8'li gruplar)
        for i in range(0, len(tags), 8):
            tag_group = tags[i:i+8]
            print(f"   {' '.join(f'{tag:8s}' for tag in tag_group)}")
    
    # Model dosya bilgisi
    if os.path.exists(MODEL_FILE):
        file_size = os.path.getsize(MODEL_FILE) / 1024  # KB
        creation_time = datetime.fromtimestamp(os.path.getctime(MODEL_FILE))
        print(f"\nğŸ’¾ Dosya Bilgileri:")
        print(f"   Dosya boyutu: {file_size:.1f} KB")
        print(f"   OluÅŸturma tar: {creation_time.strftime('%Y-%m-%d %H:%M:%S')}")


def performance_benchmark(model):
    """Performance benchmark demosu."""
    print(f"\nâš¡ PERFORMANCE BENCHMARK")
    print(f"{'='*50}")
    
    # Test cÃ¼mleleri hazÄ±rla
    test_sentences = []
    for sentences in SAMPLE_SENTENCES.values():
        test_sentences.extend(sentences)
    
    # Warm-up
    print(f"ğŸ”¥ Warm-up iÅŸlemi...")
    for sentence in test_sentences[:3]:
        words = simple_tokenize(sentence)
        model.viterbi_decode(words)
    
    # Benchmark
    print(f"ğŸƒâ€â™‚ï¸ Benchmark baÅŸlÄ±yor ({len(test_sentences)} cÃ¼mle)...")
    
    processing_times = []
    total_tokens = 0
    
    benchmark_start = time.time()
    
    for sentence in test_sentences:
        words = simple_tokenize(sentence)
        total_tokens += len(words)
        
        start_time = time.time()
        model.viterbi_decode(words)
        processing_time = time.time() - start_time
        
        processing_times.append(processing_time)
    
    total_benchmark_time = time.time() - benchmark_start
    
    # SonuÃ§larÄ± analiz et
    avg_sentence_time = sum(processing_times) / len(processing_times)
    avg_token_time = sum(processing_times) / total_tokens
    tokens_per_second = total_tokens / total_benchmark_time
    
    min_time = min(processing_times)
    max_time = max(processing_times)
    
    print(f"\nğŸ“Š Benchmark SonuÃ§larÄ±:")
    print(f"   Test cÃ¼mle sayÄ±sÄ±    : {len(test_sentences)}")
    print(f"   Toplam token sayÄ±sÄ±  : {total_tokens:,}")
    print(f"   Toplam sÃ¼re          : {total_benchmark_time:.3f} saniye")
    print(f"   Ortalama cÃ¼mle sÃ¼resi: {avg_sentence_time:.3f} saniye")
    print(f"   Ortalama token sÃ¼resi: {avg_token_time:.4f} saniye")
    print(f"   Token/saniye         : {tokens_per_second:.1f}")
    print(f"   En hÄ±zlÄ± cÃ¼mle       : {min_time:.3f} saniye")
    print(f"   En yavaÅŸ cÃ¼mle       : {max_time:.3f} saniye")
    
    # Performance kategorisi
    if tokens_per_second > 1000:
        category = "ğŸš€ Ã‡ok HÄ±zlÄ±"
    elif tokens_per_second > 500:
        category = "âš¡ HÄ±zlÄ±"
    elif tokens_per_second > 100:
        category = "âœ… Normal"
    else:
        category = "ğŸŒ YavaÅŸ"
    
    print(f"   Performance kategorisi: {category}")


def show_session_stats(session):
    """Oturum istatistiklerini gÃ¶sterir."""
    stats = session.get_stats()
    
    print(f"\nğŸ“Š OTURUM Ä°STATÄ°STÄ°KLERÄ°")
    print(f"{'='*50}")
    print(f"â° Oturum sÃ¼resi      : {stats['session_duration']:.1f} saniye")
    print(f"ğŸ“ Etiketlenen cÃ¼mle  : {stats['tagged_sentences']}")
    print(f"ğŸ”¤ Toplam token       : {stats['total_tokens']}")
    print(f"âš¡ Ä°ÅŸlem sÃ¼resi       : {stats['total_processing_time']:.3f} saniye")
    
    if stats['tagged_sentences'] > 0:
        print(f"ğŸ“Š CÃ¼mle baÅŸÄ±na       : {stats['avg_time_per_sentence']:.3f} saniye")
        print(f"ğŸ¯ Token baÅŸÄ±na       : {stats['avg_time_per_token']:.4f} saniye")
        
        efficiency = (stats['total_processing_time'] / stats['session_duration']) * 100
        print(f"ğŸ“ˆ Ä°ÅŸlem verimi       : %{efficiency:.1f}")


def show_about():
    """HakkÄ±nda bilgilerini gÃ¶sterir."""
    print(f"\nğŸ“– HAKKINDA")
    print(f"{'='*50}")
    print(f"ğŸ”§ HMM POS Tagger - TÃ¼rkÃ§e Kelime TÃ¼rÃ¼ Etiketleyici")
    print(f"ğŸ“… GeliÅŸtirme Tarihi: 2024")
    print(f"ğŸ·ï¸  Desteklenen Dil: TÃ¼rkÃ§e")
    print(f"ğŸ§  Algoritma: Hidden Markov Model + Viterbi")
    print(f"âš™ï¸  Framework: Python, Stanza, scikit-learn")
    print(f"ğŸ“Š Ã–zellikler:")
    print(f"   â€¢ TÃ¼rkÃ§e morphology desteÄŸi")
    print(f"   â€¢ OOV (Out-of-Vocabulary) kelime iÅŸleme")
    print(f"   â€¢ Add-k smoothing")
    print(f"   â€¢ Viterbi optimal path finding")
    print(f"   â€¢ CoNLL-U format desteÄŸi")
    print(f"   â€¢ Batch processing")
    print(f"   â€¢ Performance benchmarking")
    print(f"\nğŸ“ Proje YapÄ±sÄ±:")
    print(f"   â€¢ core/        - Ana modÃ¼ller")
    print(f"   â€¢ scripts/     - Ã‡alÄ±ÅŸabilir scriptler")
    print(f"   â€¢ data/        - Veri dosyalarÄ±")
    print(f"   â€¢ models/      - EÄŸitilmiÅŸ modeller")
    print(f"   â€¢ web/         - Web arayÃ¼zÃ¼")
    print(f"\nğŸ”— GeliÅŸmiÅŸ KullanÄ±m:")
    print(f"   â€¢ Web demo: python web/app.py")
    print(f"   â€¢ Evaluation: python scripts/04_evaluate.py")
    print(f"   â€¢ Training: python scripts/02_train_model.py")


def main():
    """Ana demo fonksiyonu."""
    print_banner()
    
    # Model yÃ¼kle
    model = load_model()
    if not model:
        return
    
    # Demo session baÅŸlat
    session = DemoSession()
    
    print(f"ğŸ® Demo baÅŸlatÄ±ldÄ±! Model hazÄ±r.")
    
    try:
        while True:
            print_menu()
            
            try:
                choice = input(f"\nğŸ¯ SeÃ§iminiz: ").strip().lower()
                
                if choice == 'q' or choice == 'quit' or choice == 'exit':
                    break
                elif choice == '1':
                    single_sentence_demo(model, session)
                elif choice == '2':
                    batch_tagging_demo(model, session)
                elif choice == '3':
                    sample_sentences_demo(model, session)
                elif choice == '4':
                    model_analysis_demo(model)
                elif choice == '5':
                    performance_benchmark(model)
                elif choice == '6':
                    show_session_stats(session)
                elif choice == '7':
                    show_about()
                else:
                    print(f"âŒ GeÃ§ersiz seÃ§im: {choice}")
                    
            except KeyboardInterrupt:
                print(f"\n\nğŸ‘‹ Demo sonlandÄ±rÄ±lÄ±yor...")
                break
    
    except Exception as e:
        print(f"\nâŒ Beklenmeyen hata: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Session sonuÃ§larÄ±nÄ± gÃ¶ster ve kaydet
        if session.tagged_sentences > 0:
            print(f"\n" + "="*60)
            print(f"ğŸŠ Demo TamamlandÄ±!")
            show_session_stats(session)
            session.save_log()
        
        print(f"ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")


if __name__ == '__main__':
    main() 