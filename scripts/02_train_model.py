#!/usr/bin/env python3
"""
HMM Model Training Script

Bu script CoNLL-U formatÄ±ndaki training verisini kullanarak
HMM (Hidden Markov Model) eÄŸitir ve modeli kaydeder.

Usage:
    python scripts/02_train_model.py
    
Input:
    - data/processed/train.conllu
    - data/processed/dev.conllu (opsiyonel validation)
    
Output:
    - models/hmm_model.pkl
    - models/training_report.txt
"""

import os
import sys
import time
from datetime import datetime

# Proje core modÃ¼llerini import et
sys.path.append(os.path.abspath('.'))
from core import CoNLLUReader, HMMCounts, HMMModel

# KonfigÃ¼rasyon
TRAIN_FILE = 'data/processed/train.conllu'
DEV_FILE = 'data/processed/dev.conllu'
MODEL_DIR = 'models/'
MODEL_FILE = f'{MODEL_DIR}/hmm_model.pkl'
REPORT_FILE = f'{MODEL_DIR}/training_report.txt'

# HMM Hiperparameterleri
SMOOTHING_ALPHA = 0.1        # Add-k smoothing parametresi
N_GRAM_ORDER = 2              # Bigram kullan (2-gram)
MIN_WORD_FREQ = 2             # OOV threshold
USE_MORPHOLOGY = True          # TÃ¼rkÃ§e morphology kullan


def check_input_files():
    """
    Gerekli input dosyalarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol eder.
    
    Returns:
        tuple: (train_exists, dev_exists)
    """
    train_exists = os.path.exists(TRAIN_FILE)
    dev_exists = os.path.exists(DEV_FILE)
    
    print(f"ğŸ“‚ Input dosyalarÄ± kontrol ediliyor:")
    print(f"   {'âœ…' if train_exists else 'âŒ'} Training: {TRAIN_FILE}")
    print(f"   {'âœ…' if dev_exists else 'âŒ'} Dev (opsiyonel): {DEV_FILE}")
    
    if not train_exists:
        raise FileNotFoundError(f"Training dosyasÄ± bulunamadÄ±: {TRAIN_FILE}")
    
    return train_exists, dev_exists


def load_training_data():
    """
    Training ve dev verilerini yÃ¼kler ve istatistikleri gÃ¶sterir.
    
    Returns:
        tuple: (train_reader, dev_reader)
    """
    print(f"\nğŸ“– Training verisi yÃ¼kleniyor: {TRAIN_FILE}")
    train_reader = CoNLLUReader(TRAIN_FILE)
    
    print(f"âœ… Training verisi yÃ¼klendi:")
    print(f"   CÃ¼mle sayÄ±sÄ±: {train_reader.get_sentence_count():,}")
    print(f"   Token sayÄ±sÄ±: {train_reader.get_token_count():,}")
    print(f"   Kelime Ã§eÅŸitliliÄŸi: {len(train_reader.get_vocabulary()):,}")
    print(f"   POS tag Ã§eÅŸitliliÄŸi: {len(train_reader.get_tag_set()):,}")
    
    # Dev verisi varsa yÃ¼kle
    dev_reader = None
    if os.path.exists(DEV_FILE):
        print(f"\nğŸ“– Dev verisi yÃ¼kleniyor: {DEV_FILE}")
        dev_reader = CoNLLUReader(DEV_FILE)
        print(f"âœ… Dev verisi yÃ¼klendi:")
        print(f"   CÃ¼mle sayÄ±sÄ±: {dev_reader.get_sentence_count():,}")
        print(f"   Token sayÄ±sÄ±: {dev_reader.get_token_count():,}")
    
    return train_reader, dev_reader


def show_data_statistics(train_reader, dev_reader=None):
    """
    Veri istatistiklerini detaylÄ± ÅŸekilde gÃ¶sterir.
    
    Args:
        train_reader: Training data reader
        dev_reader: Dev data reader (opsiyonel)
    """
    print(f"\nğŸ“Š Veri Ä°statistikleri:")
    print(f"{'='*60}")
    
    # Training stats
    vocab = train_reader.get_vocabulary()
    tags = train_reader.get_tag_set()
    
    print(f"Training Set:")
    print(f"  CÃ¼mle sayÄ±sÄ±    : {train_reader.get_sentence_count():,}")
    print(f"  Token sayÄ±sÄ±    : {train_reader.get_token_count():,}")
    print(f"  Kelime Ã§eÅŸitliliÄŸi: {len(vocab):,}")
    print(f"  POS tag sayÄ±sÄ±  : {len(tags):,}")
    
    # POS tag daÄŸÄ±lÄ±mÄ±
    print(f"\nğŸ·ï¸  POS Tag DaÄŸÄ±lÄ±mÄ± (ilk 10):")
    tag_stats = train_reader.get_tag_statistics()
    for tag, count in sorted(tag_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
        percentage = (count / train_reader.get_token_count()) * 100
        print(f"   {tag:8s}: {count:6,d} (%{percentage:4.1f})")
    
    # En sÄ±k kelimeler
    print(f"\nğŸ”¤ En SÄ±k Kelimeler (ilk 10):")
    word_stats = train_reader.get_word_statistics()
    for word, count in sorted(word_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
        percentage = (count / train_reader.get_token_count()) * 100
        print(f"   {word:15s}: {count:4,d} (%{percentage:4.1f})")
    
    # Dev set varsa
    if dev_reader:
        print(f"\nDev Set:")
        print(f"  CÃ¼mle sayÄ±sÄ±    : {dev_reader.get_sentence_count():,}")
        print(f"  Token sayÄ±sÄ±    : {dev_reader.get_token_count():,}")
        
        # OOV analizi
        dev_vocab = dev_reader.get_vocabulary()
        oov_words = dev_vocab - vocab
        oov_rate = len(oov_words) / len(dev_vocab) * 100
        print(f"  OOV kelime sayÄ±sÄ±: {len(oov_words):,} (%{oov_rate:.1f})")


def train_hmm_model(train_reader):
    """
    HMM modelini eÄŸitir.
    
    Args:
        train_reader: Training data reader
    
    Returns:
        HMMModel: EÄŸitilmiÅŸ model
    """
    print(f"\nğŸ¤– HMM Model EÄŸitimi BaÅŸlÄ±yor")
    print(f"{'='*50}")
    print(f"Hiperparametreler:")
    print(f"  Smoothing Alpha : {SMOOTHING_ALPHA}")
    print(f"  N-gram Order    : {N_GRAM_ORDER}")
    print(f"  Min Word Freq   : {MIN_WORD_FREQ}")
    print(f"  Morphology      : {'Evet' if USE_MORPHOLOGY else 'HayÄ±r'}")
    
    start_time = time.time()
    
    # Model oluÅŸtur ve eÄŸit
    model = HMMModel()
    
    print(f"\nğŸ”¢ N-gram sayÄ±mlarÄ± hesaplanÄ±yor...")
    model.train(train_reader, smoothing=SMOOTHING_ALPHA)
    
    training_time = time.time() - start_time
    print(f"âœ… Model eÄŸitimi tamamlandÄ± ({training_time:.2f} saniye)")
    
    return model


def evaluate_on_dev(model, dev_reader):
    """
    Modeli dev set Ã¼zerinde deÄŸerlendirir.
    
    Args:
        model: EÄŸitilmiÅŸ HMM model
        dev_reader: Dev data reader
    
    Returns:
        dict: DeÄŸerlendirme sonuÃ§larÄ±
    """
    if not dev_reader:
        return None
    
    print(f"\nğŸ” Dev Set Ãœzerinde DeÄŸerlendirme")
    print(f"{'='*40}")
    
    total_tokens = 0
    correct_tags = 0
    
    start_time = time.time()
    
    first = True  # Sadece ilk cÃ¼mle iÃ§in detaylÄ± Ã§Ä±ktÄ±
    for sentence_data in dev_reader:
        words = [token['form'] for token in sentence_data]
        true_tags = [token['upos'] for token in sentence_data]
        
        # Viterbi ile tahmin yap
        predicted_tags = model.viterbi_decode(words)
        
        # Uzunluk kontrolÃ¼ ve Ã¶rnek Ã§Ä±ktÄ±
        if len(words) != len(predicted_tags):
            print(f"UYARI: {len(words)} kelime, {len(predicted_tags)} tag")
        if first:
            print("\nÄ°lk cÃ¼mle iÃ§in karÅŸÄ±laÅŸtÄ±rma:")
            for w, t, p in zip(words, true_tags, predicted_tags):
                print(f"{w:15s} | {t:8s} | {p:8s}")
            first = False
        
        # DoÄŸruluÄŸu hesapla
        total_tokens += len(words)
        correct_tags += sum(1 for true, pred in zip(true_tags, predicted_tags) if true == pred)
    
    eval_time = time.time() - start_time
    accuracy = (correct_tags / total_tokens) * 100
    
    results = {
        'total_tokens': total_tokens,
        'correct_tags': correct_tags,
        'accuracy': accuracy,
        'evaluation_time': eval_time
    }
    
    print(f"Total tokens: {total_tokens:,}")
    print(f"Correct tags: {correct_tags:,}")
    print(f"Accuracy    : {accuracy:.2f}%")
    print(f"Eval time   : {eval_time:.2f} seconds")
    
    return results


def save_model_and_report(model, train_reader, dev_reader=None, dev_results=None):
    """
    Modeli ve eÄŸitim raporunu kaydeder.
    
    Args:
        model: EÄŸitilmiÅŸ HMM model
        train_reader: Training data reader
        dev_reader: Dev data reader
        dev_results: Dev deÄŸerlendirme sonuÃ§larÄ±
    """
    # Model dizinini oluÅŸtur
    os.makedirs(MODEL_DIR, exist_ok=True)
    
    print(f"\nğŸ’¾ Model kaydediliyor: {MODEL_FILE}")
    model.save(MODEL_FILE)
    print(f"âœ… Model kaydedildi")
    
    # Training report oluÅŸtur
    print(f"ğŸ“„ EÄŸitim raporu oluÅŸturuluyor: {REPORT_FILE}")
    
    with open(REPORT_FILE, 'w', encoding='utf-8') as f:
        f.write("HMM POS Tagger - Training Report\n")
        f.write("=" * 50 + "\n")
        f.write(f"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # KonfigÃ¼rasyon
        f.write("Configuration:\n")
        f.write(f"  Smoothing Alpha    : {SMOOTHING_ALPHA}\n")
        f.write(f"  N-gram Order       : {N_GRAM_ORDER}\n")
        f.write(f"  Min Word Frequency : {MIN_WORD_FREQ}\n")
        f.write(f"  Turkish Morphology : {USE_MORPHOLOGY}\n\n")
        
        # Training data stats
        f.write("Training Data:\n")
        f.write(f"  File              : {TRAIN_FILE}\n")
        f.write(f"  Sentences         : {train_reader.get_sentence_count():,}\n")
        f.write(f"  Tokens            : {train_reader.get_token_count():,}\n")
        f.write(f"  Vocabulary Size   : {len(train_reader.get_vocabulary()):,}\n")
        f.write(f"  POS Tags          : {len(train_reader.get_tag_set()):,}\n")
        f.write(f"  Tags: {', '.join(sorted(train_reader.get_tag_set()))}\n\n")
        
        # Model stats
        model_stats = model.get_model_statistics()
        f.write("Model Statistics:\n")
        f.write(f"  Emission Entries  : {model_stats.get('emission_pairs', 0):,}\n")
        f.write(f"  Transition Entries: {model_stats.get('transition_pairs', 0):,}\n")
        f.write(f"  Vocabulary Size   : {model_stats.get('vocab_size', 0):,}\n")
        f.write(f"  Tag Set Size      : {model_stats.get('tag_count', 0):,}\n\n")
        
        # Dev results varsa
        if dev_results:
            f.write("Development Set Evaluation:\n")
            f.write(f"  File          : {DEV_FILE}\n")
            f.write(f"  Total Tokens  : {dev_results['total_tokens']:,}\n")
            f.write(f"  Correct Tags  : {dev_results['correct_tags']:,}\n")
            f.write(f"  Accuracy      : {dev_results['accuracy']:.2f}%\n")
            f.write(f"  Eval Time     : {dev_results['evaluation_time']:.2f}s\n\n")
        
        # Top POS tags
        tag_stats = train_reader.get_tag_statistics()
        f.write("POS Tag Distribution:\n")
        for tag, count in sorted(tag_stats.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / train_reader.get_token_count()) * 100
            f.write(f"  {tag:8s}: {count:6,d} ({percentage:4.1f}%)\n")
    
    print(f"âœ… EÄŸitim raporu kaydedildi")


def show_model_info(model):
    """
    EÄŸitilmiÅŸ model hakkÄ±nda bilgi gÃ¶sterir.
    
    Args:
        model: EÄŸitilmiÅŸ HMM model
    """
    print(f"\nğŸ“‹ Model Bilgileri:")
    print(f"{'='*40}")
    
    stats = model.get_model_statistics()
    print(f"Emission parametreleri : {stats.get('emission_pairs', 0):,}")
    print(f"Transition parametreleri: {stats.get('transition_pairs', 0):,}")
    print(f"Vocabulary boyutu       : {stats.get('vocab_size', 0):,}")
    print(f"POS tag sayÄ±sÄ±          : {stats.get('tag_count', 0):,}")
    
    # Dosya boyutu
    if os.path.exists(MODEL_FILE):
        model_size = os.path.getsize(MODEL_FILE) / 1024  # KB
        print(f"Model dosya boyutu      : {model_size:.1f} KB")


def main():
    """
    Ana eÄŸitim fonksiyonu.
    """
    print("ğŸš€ HMM Model EÄŸitimi BaÅŸlÄ±yor")
    print("=" * 50)
    
    try:
        # 1. Input dosyalarÄ±nÄ± kontrol et
        train_exists, dev_exists = check_input_files()
        
        # 2. Veriyi yÃ¼kle
        train_reader, dev_reader = load_training_data()
        
        # 3. Veri istatistiklerini gÃ¶ster
        show_data_statistics(train_reader, dev_reader)
        
        # 4. Modeli eÄŸit
        model = train_hmm_model(train_reader)
        
        # 5. Dev set'te deÄŸerlendir (varsa)
        dev_results = evaluate_on_dev(model, dev_reader) if dev_reader else None
        
        # 6. Model ve raporu kaydet
        save_model_and_report(model, train_reader, dev_reader, dev_results)
        
        # 7. Model bilgilerini gÃ¶ster
        show_model_info(model)
        
        print(f"\nğŸ‰ Model eÄŸitimi baÅŸarÄ±yla tamamlandÄ±!")
        print(f"Model dosyasÄ±: {MODEL_FILE}")
        print(f"Rapor dosyasÄ±: {REPORT_FILE}")
        print(f"\nSonraki adÄ±m: python scripts/03_test_model.py")
        
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main() 